{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "66c99cba-6f27-48a5-b3ca-81014f3adeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import random\n",
    "from scipy import stats\n",
    "from ddeint import ddeint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.linalg import qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322e3cd2-75ad-4028-9bdd-c554cd255d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reservoir generation \n",
    "def gen_matrix(shape, sparsity, sd=1, mean=0, loc_seed=100, val_seed=100, pdf=\"gaussian\", seeded=True):\n",
    "    \n",
    "    def seeded_rvs_gauss(array_len):\n",
    "            return stats.norm(loc=mean, scale=sd).rvs(random_state = val_seed, size=array_len)\n",
    "\n",
    "    def seeded_rvs_uniform(array_len):\n",
    "        return stats.uniform(loc=mean, scale=sd).rvs(random_state = val_seed, size=array_len)\n",
    "\n",
    "    m = shape[0]\n",
    "    n = shape[1]\n",
    "\n",
    "    if seeded == True:\n",
    "        \n",
    "        if pdf == \"gaussian\":\n",
    "            M = random(m, n, density=sparsity, random_state=loc_seed, data_rvs=seeded_rvs_gauss).A\n",
    "            return M\n",
    "\n",
    "        if pdf == \"uniform\":\n",
    "            M = random(m, n, density=sparsity, random_state=loc_seed, data_rvs=seeded_rvs_uniform).A\n",
    "            return M\n",
    "\n",
    "        if pdf == \"ones\":\n",
    "            M = random(m, n, density = sparsity, random_state=loc_seed, data_rvs=np.ones).A\n",
    "            return M\n",
    "        else: \n",
    "            print(\"No such pdf\")\n",
    "            \n",
    "    elif seeded == False:\n",
    "        \n",
    "        if pdf == \"gaussian\":\n",
    "            unseeded_rvs = stats.norm(loc=mean, scale=sd).rvs\n",
    "            M = random(m, n, density=sparsity, data_rvs=unseeded_rvs).A\n",
    "            return M\n",
    "\n",
    "        if pdf == \"uniform\":\n",
    "            unseeded_rvs = stats.uniform(loc=mean, scale=sd).rvs\n",
    "            M = random(m, n, density=sparsity, data_rvs=unseeded_rvs).A\n",
    "            return M\n",
    "\n",
    "        if pdf == \"ones\":\n",
    "            M = random(m, n, density = sparsity, data_rvs=np.ones).A\n",
    "            return M\n",
    "        else: \n",
    "            print(\"No such pdf\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Seeded was neither true nor false\")\n",
    "\n",
    "def spectral_radius(mat):\n",
    "    max_abs_eigenvalue = -1\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(mat)\n",
    "    for eigenvalue in eigenvalues:\n",
    "        if abs(eigenvalue) > max_abs_eigenvalue:\n",
    "            max_abs_eigenvalue = abs(eigenvalue)\n",
    "    return max_abs_eigenvalue\n",
    "\n",
    "def spectral_radius_matrix(mat, desired_spec_rad):\n",
    "    M_sr = spectral_radius(mat)\n",
    "    if M_sr == 0:\n",
    "        return mat\n",
    "    else:\n",
    "        mat = mat*(desired_spec_rad/M_sr)\n",
    "        return mat\n",
    "    \n",
    "# ESN equations\n",
    "def sigma(value):\n",
    "    return np.tanh(value)\n",
    "\n",
    "def state(x_prev, z_curr, A, gamma, C, s, zeta):\n",
    "    z_curr = np.atleast_2d(z_curr)\n",
    "    x_curr = sigma(np.matmul(A, x_prev) + gamma*np.matmul(C, z_curr) + s*zeta)\n",
    "    return x_curr\n",
    "\n",
    "def observation(x_curr, w):\n",
    "    z_next = np.matmul(np.transpose(w), x_curr)\n",
    "    return z_next\n",
    "\n",
    "# Training equations\n",
    "def listening(training_data, x_0, A, gamma, C, s, zeta):\n",
    "    state_dict = {'all_states': None,\n",
    "                  'best_weight': None, \n",
    "                  'input_data': None}\n",
    "    \n",
    "    T = len(training_data)\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        if t == 1:\n",
    "            x_curr = x_0\n",
    "            X = np.array(x_curr)\n",
    "            z_curr = training_data.loc[t]['tau17']\n",
    "            Z = np.atleast_2d(np.array([z_curr]))\n",
    "        else:\n",
    "            x_curr = state(x_curr, z_curr, A, gamma, C, s, zeta)\n",
    "            X = np.column_stack((X, x_curr))\n",
    "            z_curr = training_data.loc[t]['tau17']\n",
    "            Z = np.column_stack((Z, z_curr))\n",
    "            \n",
    "    state_dict['last_state'] = x_curr\n",
    "    state_dict['all_states'] = X\n",
    "    state_dict['input_data'] = Z\n",
    "    \n",
    "    return state_dict\n",
    "    \n",
    "def regression_sol(ld, state_dict, N):\n",
    "    X = state_dict['all_states']\n",
    "    Z = state_dict['input_data']\n",
    "    \n",
    "    X = X[:, 1001:]\n",
    "    Z = Z[:, 1001:]\n",
    "\n",
    "    X_transpose = X.transpose()\n",
    "    Z_transpose = Z.transpose()\n",
    "    XZ_transpose = np.matmul(X, Z_transpose)\n",
    "    \n",
    "    inverse_term = np.linalg.inv(np.matmul(X, X_transpose) + ld*np.identity(N))\n",
    "    W_best = np.matmul(inverse_term, XZ_transpose)\n",
    "    \n",
    "    return W_best\n",
    "\n",
    "def prediction(state_dict, weight, testing_data, training_data, A, gamma, C, s, zeta, platt_err):\n",
    "    prediction_dict = {'testing_error': None,\n",
    "                       'z_actuals': None,\n",
    "                       'z_predictions': None}\n",
    "    \n",
    "    z_actuals = []\n",
    "    z_predictions = []\n",
    "    \n",
    "    last_state = state_dict.get('last_state')\n",
    "    testing_error = 0\n",
    "    \n",
    "    T = len(training_data)\n",
    "    T_bar = len(testing_data)\n",
    "    \n",
    "    weight_sum = 0\n",
    "    x_prev = last_state\n",
    "    for t_bar in range(T+1, T+T_bar+1):\n",
    "        z_predict = observation(x_prev, weight)[0][0]\n",
    "        x_prev = state(x_prev, z_predict, A, gamma, C, s, zeta)\n",
    "        z_predictions.append(z_predict)\n",
    "        \n",
    "        z_actual = testing_data.loc[t_bar]['tau17']\n",
    "        z_actuals.append(z_actual)\n",
    "        \n",
    "        if platt_err == True:\n",
    "            testing_error = testing_error + ((z_predict - z_actual)**2)*np.exp(-((t_bar-T)/T_bar))\n",
    "            weight_sum = weight_sum + np.exp(-((t_bar-T)/T_bar))\n",
    "        else:    \n",
    "            testing_error = testing_error + (z_predict - z_actual)**2\n",
    "            weight_sum = weight_sum + 1\n",
    "    \n",
    "    prediction_dict['testing_error'] = testing_error/weight_sum\n",
    "    prediction_dict['z_actuals'] = z_actuals\n",
    "    prediction_dict['z_predictions'] = z_predictions        \n",
    "        \n",
    "    return prediction_dict\n",
    "\n",
    "def training_error(state_dict, weight, training_data):\n",
    "    training_error_dict = {'training_error': None,\n",
    "                           'z_actuals': None,\n",
    "                           'z_predictions': None}\n",
    "    \n",
    "    z_actuals = []\n",
    "    z_predictions = []\n",
    "    \n",
    "    X = state_dict.get('all_states')\n",
    "    \n",
    "    X = X[:, 1001:]\n",
    "    \n",
    "    training_error = 0\n",
    "    \n",
    "    T = len(training_data)\n",
    "    \n",
    "    for t in range(1001, T):\n",
    "        x_prev = X[:, t-1001]\n",
    "        z_predict = observation(x_prev, weight)[0]\n",
    "        \n",
    "        z_predictions.append(z_predict)\n",
    "        z_actual = training_data.loc[t]['tau17']\n",
    "        z_actuals.append(z_actual)\n",
    "        training_error = training_error + (z_predict - z_actual)**2\n",
    "        \n",
    "    training_error = training_error/(T-1000)\n",
    "    \n",
    "    training_error_dict['training_error'] = training_error\n",
    "    training_error_dict['z_actuals'] = z_actuals\n",
    "    training_error_dict['z_predictions'] = z_predictions\n",
    "        \n",
    "    return training_error_dict\n",
    "\n",
    "# data generation functions\n",
    "def generate_MG_data(init_val, tau, a, b, n):\n",
    "    def MackeyGlass(z, t):\n",
    "        return (a * z(t - tau)) / (1 + z(t - tau)**n) - b*z(t)\n",
    "\n",
    "    def initial(t):\n",
    "        return init_val\n",
    "\n",
    "    time_space = np.arange(0, 5000, 1)\n",
    "\n",
    "    z_solution_new = ddeint(MackeyGlass, initial, time_space)\n",
    "    z_solution_new  = [ data_pt[0] for data_pt in z_solution_new[1:] ]\n",
    "    z_solution_new.insert(0, init_val)\n",
    "    z_solution_new = [ np.tanh(unshifted_val-1) for unshifted_val in z_solution_new ]\n",
    "    z_sol_new_df = pd.DataFrame(z_solution_new, columns=['tau17'])\n",
    "\n",
    "    z_sol_new_df.index = z_sol_new_df.index + 1\n",
    "    training_data = z_sol_new_df.loc[1:3001]\n",
    "    testing_data = z_sol_new_df.loc[3002:]\n",
    "    \n",
    "    return training_data, testing_data\n",
    "\n",
    "# miscellaneous plotting functions\n",
    "def state_plot(state_dict, plotwith_init, node=0):\n",
    "    X = state_dict.get('all_states')\n",
    "    if plotwith_init == True:\n",
    "        state_plot, state_ax = plt.subplots(figsize=(20,5))\n",
    "        state_ax.plot(X[node][:])\n",
    "        state_ax.set_title('Plot of States at node {}'.format(node))\n",
    "        state_ax.set_xlabel('time')\n",
    "        state_ax.set_ylabel('state of node {}'.format(node))\n",
    "        \n",
    "        return (np.amin(X[node][:]), np.amax(X[node][:]))\n",
    "    \n",
    "    if plotwith_init == False:\n",
    "        state_plot, state_ax = plt.subplots(figsize=(20,5))\n",
    "        state_ax.plot(X[node][1001:])\n",
    "        state_ax.set_title('Plot of States at node {}'.format(node))\n",
    "        state_ax.set_xlabel('time')\n",
    "        state_ax.set_ylabel('state of node {}'.format(node))\n",
    "    \n",
    "        return (np.amin(X[node][1001:]), np.amax(X[node][1001:]))\n",
    "                \n",
    "def hist_accuracy_plot(actuals, predictions, with_bars=False):\n",
    "    if with_bars == False:\n",
    "        sns.kdeplot(actuals, label='actual', shade=True, color='red')\n",
    "        sns.kdeplot(predictions, label='prediction', shade=True, color='skyblue')\n",
    "        plt.legend()\n",
    "        \n",
    "    if with_bars == True:\n",
    "        sns.histplot(actuals, label='actual', color='red', kde=True)\n",
    "        sns.histplot(predictions, label='prediction', color='skyblue', kde=True)\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5a7a28f-0ef3-4eb4-ba57-f12db8931c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/Library/Python/3.8/lib/python/site-packages/ddeint/ddeint.py:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([g(tt[0])] + results)\n"
     ]
    }
   ],
   "source": [
    "data = generate_MG_data(1.2, 17, 0.2, 0.1, 10)\n",
    "\n",
    "warmup_data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2ddded69-9d5a-4682-b81e-a6a50266ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "ld = 10**(-14)\n",
    "C = gen_matrix(shape=(N,1), sparsity=0.6, sd=4, mean=-2, pdf=\"uniform\", seeded=True, loc_seed=407, val_seed=408)\n",
    "gamma = 0.8\n",
    "A = gen_matrix(shape=(N,N), sparsity=0.01, sd=2, mean=-1, pdf=\"uniform\", seeded=True, loc_seed=500, val_seed=508)\n",
    "spec_rad = 1.2\n",
    "A = spectral_radius_matrix(A, spec_rad)\n",
    "s = 0.2\n",
    "zeta = gen_matrix(shape=(N,1), sparsity=0.6, pdf=\"ones\", loc_seed=400, seeded=True)\n",
    "x_0 = np.zeros(shape=(N,1), dtype=float)\n",
    "\n",
    "state_dict = listening(warmup_data, x_0, A, gamma, C, s, zeta)\n",
    "weights = regression_sol(ld, state_dict, N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "53f41510-0a32-4037-844e-571e60682fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf0_px(x): # (N,1) vector\n",
    "    return csc_matrix(weights.transpose())\n",
    "\n",
    "def outer_term(x, z):\n",
    "    csc_A = csc_matrix(A)\n",
    "    csc_C = csc_matrix(C)\n",
    "    csc_zeta = csc_matrix(zeta)\n",
    "    \n",
    "    tanh_term = np.tanh(csc_A*x + gamma*csc_C*z + s*csc_zeta)\n",
    "    \n",
    "    return csc_matrix(1 - np.power(tanh_term, 2))\n",
    "\n",
    "def pf_px(x, z): # (N,1) vector and scalar\n",
    "    outer = outer_term(x, z)\n",
    "    return outer.multiply(A)\n",
    "    \n",
    "def pf_pz(x, z): # (N,1) vector and scalar\n",
    "    outer = outer_term(x, z)\n",
    "    return outer.multiply(C)\n",
    "\n",
    "def gram_schmidt(u):\n",
    "    alpha = np.zeros(shape=(N,))\n",
    "    for j in range(N):\n",
    "        for k in range(j):\n",
    "            u[: , j] = u[: , j] - np.dot(u[: , k], u[: , j]) * u[: , k]\n",
    "        alpha[j] = np.linalg.norm(u[: , j])\n",
    "        u[:, j] = u[: , j] / alpha[j]\n",
    "    return u, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3323724e-147f-48c3-a7df-d3f9fadb02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "T_norm = 5\n",
    "delta = 10**(-7)\n",
    "h = 1   # needs to correspond to the step size in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "39bff1c7-af21-4cee-9658-a9346e69358f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/6rj9phvn31v9b8yqm_zdkgd40000gn/T/ipykernel_89828/4190632070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mDelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mDelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mDelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgram_schmidt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mLambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4l/6rj9phvn31v9b8yqm_zdkgd40000gn/T/ipykernel_89828/2421641835.py\u001b[0m in \u001b[0;36mgram_schmidt\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Delta = delta * np.identity(N)\n",
    "\n",
    "Lambda = np.zeros(shape=(N, ))\n",
    "Lambda_prev = np.zeros(shape=(N, ))\n",
    "\n",
    "x_prev = state_dict['last_state']\n",
    "z_curr = state_dict['input_data'][0, -1]\n",
    "\n",
    "J0 = pf0_px(x_prev)\n",
    "\n",
    "for t in range(0, T):\n",
    "    \n",
    "    x_curr = state(x_prev, z_curr, A, gamma, C, s, zeta)\n",
    "    z_curr = observation(x_curr, weights) \n",
    "    x_prev = x_curr\n",
    "    \n",
    "    J1 = pf_px(x_curr, z_curr) \n",
    "    J2 = pf_pz(x_curr, z_curr)\n",
    "    J = J1 + J2*J0\n",
    "    Delta = J*Delta\n",
    "    \n",
    "    Delta, alpha = gram_schmidt(Delta)\n",
    "    Lambda = Lambda + np.log(alpha)\n",
    "\n",
    "    Lambda_prev = Lambda\n",
    "\n",
    "Lambda = Lambda/(T*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92970131-c635-47d8-94ff-ba09a2bbc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaplan-Yorke dimension\n",
    "\n",
    "sum_Lambda = 0\n",
    "\n",
    "D_KY = 0\n",
    "\n",
    "for Lambda_id in range(0, len(Lambda)):\n",
    "    sum_Lambda = sum_Lambda + Lambda[Lambda_id]\n",
    "    if sum_Lambda < 0:\n",
    "        D_KY = Lambda_id - 1 - ((sum_Lambda - Lambda[Lambda_id])/Lambda[Lambda_id])\n",
    "        \n",
    "D_KY = D_KY + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
